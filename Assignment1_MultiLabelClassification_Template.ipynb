{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# import other useful packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Load the Yeast Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('yeast.csv')\n",
    "data = np.array(dataset.iloc[:,:103])\n",
    "functions = np.array(dataset.iloc[:,103:])\n",
    "functions[39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the Binary Relevance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, add_noise = False):\n",
    "        self.add_noise = add_noise\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, data, functions):    \n",
    "        # Create a new empty dictionary into which we will store relevance\n",
    "        self.relevances_ = dict()\n",
    "\n",
    "        # Iterate all functioins\n",
    "        for i in range(14):\n",
    "            status = functions[:,i]\n",
    "            status = status.T\n",
    "            self.relevances_[i] = BaggingClassifier(n_estimators=10, random_state=0).fit(data, status)\n",
    "        \n",
    "        # Return the classifier\n",
    "        return self\n",
    "            \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['relevances_'])\n",
    "\n",
    "        # Initialise an empty list to store the predictions made\n",
    "        pos_functions = list()\n",
    "        \n",
    "        # Iterate all functioins to predict\n",
    "        for i in range(14):\n",
    "            pos_functions.append(self.relevances_[i].predict(X))\n",
    "            \n",
    "        return np.array(pos_functions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = BinaryRelevanceClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevanceClassifier(add_noise=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(np.array(dataset.iloc[:40,:103]), np.array(dataset.iloc[:40,103:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(np.array(dataset.iloc[41:49,:103]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the Binary Relevance Algorithm with Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRUnderSample(BaseEstimator, ClassifierMixin):\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, under_sampling='undersampling'):\n",
    "        self.under_sampling = under_sampling\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, data, functions):\n",
    "         # Create a new empty dictionary into which we will store relevance\n",
    "        self.relevances_ = dict()\n",
    "        \n",
    "        # Add an option to under-sample\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        \n",
    "        # Iterate all functioins\n",
    "        for i in range(14):\n",
    "            status = functions[:,i]\n",
    "            status = status.T\n",
    "\n",
    "            # Under-sample data and status\n",
    "            if self.under_sampling == 'undersampling':\n",
    "                temp_data, status = rus.fit_sample(data,status)\n",
    "                \n",
    "            self.relevances_[i] = BaggingClassifier(n_estimators=10, random_state=0).fit(temp_data, status)\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['relevances_'])\n",
    "        \n",
    "        # Initialise an empty list to store the predictions made\n",
    "        pos_functions = list()\n",
    "\n",
    "        # Iterate all functioins to predict\n",
    "        for  i in range(14):\n",
    "            pos_functions.append(self.relevances_[i].predict(X))\n",
    "            \n",
    "        return np.array(pos_functions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = BRUnderSample(under_sampling='undersampling')\n",
    "my_model.fit(np.array(dataset.iloc[:1000,:103]), np.array(dataset.iloc[:1000,103:]))\n",
    "my_model.predict(np.array(dataset.iloc[1001:1009,:103]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of Different Binary Relevance Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Implement the Classifier Chains Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "class ClassChainsClassifier(BaseEstimator, ClassifierMixin):\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, add_noise = False):\n",
    "        self.add_noise = add_noise\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, data, functions):    \n",
    "        # Create a new empty dictionary into which we will store relevance\n",
    "        self.relevances_ = dict()\n",
    "\n",
    "        # Iterate all functioins\n",
    "        for i in range(14):\n",
    "            status = functions[:,i]\n",
    "            status_squeeze = np.squeeze(status)\n",
    "            # print(status_squeeze.shape)\n",
    "            # print(type(functions))\n",
    "            # print(type(data))\n",
    "            self.relevances_[i] = BaggingClassifier(n_estimators=10, random_state=0).fit(data, status_squeeze)\n",
    "            data = np.concatenate((data,np.reshape(status_squeeze,(data.shape[0],1))),axis=1)\n",
    "            \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['relevances_'])\n",
    "\n",
    "        # Initialise an empty list to store the predictions made\n",
    "        pos_functions = list()\n",
    "        \n",
    "        # Iterate all functioins to predict\n",
    "        for i in range(14):\n",
    "            j = 103+i\n",
    "            pos_functions.append(self.relevances_[i].predict(X[:,:j]))\n",
    "            \n",
    "        return np.array(pos_functions).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Evaluate the Performance of the Classifier Chains Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your reflection here (max 300 words)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
